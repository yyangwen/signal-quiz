[
  {
    "id": 29,
    "chapter": "第二章 参数估计理论",
    "question": "信号处理的基本任务是利用(___)作出关于信号与（或）系统的某种(___)。",
    "text": "信号处理的基本任务是利用(观测数据)作出关于信号与（或）系统的某种(统计决策)。",
    "answers": ["观测数据", "统计决策"]
  },
  {
    "id": 30,
    "chapter": "第二章 参数估计理论",
    "question": "信号处理有(___)和(___)之分。前者又称(___)，不涉及产生信号的系统，主要工具是 Fourier 变换。后者也称(___)，将信号看作是系统被激励之后的输出，其主要工具是系统与信号的模型参数估计。",
    "text": "信号处理有(经典信号处理)和(现代信号处理)之分。前者又称(非参数化信号处理)，不涉及产生信号的系统，主要工具是 Fourier 变换。后者也称(参数化信号处理)，将信号看作是系统被激励之后的输出，其主要工具是系统与信号的模型参数估计。",
    "answers": ["经典信号处理", "现代信号处理", "非参数化信号处理", "参数化信号处理"]
  },
  {
    "id": 31,
    "chapter": "第二章 参数估计理论",
    "question": "假定研究的问题具有某种数学模型，如正态分布，二项分布，再用已知类别的学习样本估计里面的参数，该估计方法称为(___)。",
    "text": "假定研究的问题具有某种数学模型，如正态分布，二项分布，再用已知类别的学习样本估计里面的参数，该估计方法称为(参数估计)。",
    "answers": ["参数估计"]
  },
  {
    "id": 32,
    "chapter": "第二章 参数估计理论",
    "question": "不假定数学模型，用已知类别的学习样本的先验知识直接估计数学模型，该估计方法称为(___)。",
    "text": "不假定数学模型，用已知类别的学习样本的先验知识直接估计数学模型，该估计方法称为(非参数估计)。",
    "answers": ["非参数估计"]
  },
  {
    "id": 33,
    "chapter": "第二章 参数估计理论",
    "question": "无偏估计一定是(___)。",
    "text": "无偏估计一定是(渐进无偏的)。",
    "answers": ["渐进无偏的"]
  },
  {
    "id": 34,
    "chapter": "第二章 参数估计理论",
    "question": "渐进无偏估计是对待估计量进行(___)后，估计出来的均值与真实值(___)，而估计误差有向(___)靠近的趋势。而无偏估计要求对待估计量进行(___)后，其估计偏差必须是(___)。",
    "text": "渐进无偏估计是对待估计量进行(无穷次估计)后，估计出来的均值与真实值(一样)，而估计误差有向(零)靠近的趋势。而无偏估计要求对待估计量进行(有限次估计)后，其估计偏差必须是(零)。",
    "answers": ["无穷次估计", "一样", "零", "有限次估计", "零"]
  },
  {
    "id": 35,
    "chapter": "第二章 参数估计理论",
    "question": "在实际的功率谱估计中，常常使用(___)，由于估计出来的功率谱的方差比较小。",
    "text": "在实际的功率谱估计中，常常使用(渐进无偏估计)，由于估计出来的功率谱的方差比较小。",
    "answers": ["渐进无偏估计"]
  },
  {
    "id": 36,
    "chapter": "第二章 参数估计理论",
    "question": "(___) 、(___)与(___)是估计子具有的统计性能，它们描述的是当样本趋于(___)时估计子的性能，统称为(___)。",
    "text": "(无偏性) 、(渐近无偏性)与(一致性)是估计子具有的统计性能，它们描述的是当样本趋于(无穷大)时估计子的性能，统称为(大样本性能)。",
    "answers": ["无偏性", "渐近无偏性", "一致性", "无穷大", "大样本性能"]
  },
  {
    "id": 37,
    "chapter": "第二章 参数估计理论",
    "question": "常用的估计量是(___) 、(___) 、(___)和(___)。",
    "text": "常用的估计量是(均值估计) 、(方差估计) 、(自相关估计)和(互相关估计)。",
    "answers": ["均值估计", "方差估计", "自相关估计", "互相关估计"]
  },
  {
    "id": 38,
    "chapter": "第二章 参数估计理论",
    "question": "假定随机信号 x (t )隐藏有真实参数θ , 根据信号的一次实现x ，可以得到θ 的一个(___)。",
    "text": "假定随机信号 x (t )隐藏有真实参数θ , 根据信号的一次实现x ，可以得到θ 的一个(估计子)。",
    "answers": ["估计子"]
  },
  {
    "id": 39,
    "chapter": "第二章 参数估计理论",
    "question": "在真实参数θ 已知的条件下，样本 X 获得估计量是否最优，可由(___)来评估。",
    "text": "在真实参数θ 已知的条件下，样本 X 获得估计量是否最优，可由(品质函数)来评估。",
    "answers": ["品质函数"]
  },
  {
    "id": 40,
    "chapter": "第二章 参数估计理论",
    "question": "当真实参数θ 已给定的条件下，随机变量x 的品质函数V 定义为(___)相对于真实参数θ 的偏导数。",
    "text": "当真实参数θ 已给定的条件下，随机变量x 的品质函数V 定义为(条件分布密度函数的对数)相对于真实参数θ 的偏导数。",
    "answers": ["条件分布密度函数的对数"]
  },
  {
    "id": 41,
    "chapter": "第二章 参数估计理论",
    "question": "由于品质函数的均值为(___)，故其方差等于品质函数的(___)。",
    "text": "由于品质函数的均值为(零)，故其方差等于品质函数的(二阶矩)。",
    "answers": ["零", "二阶矩"]
  },
  {
    "id": 42,
    "chapter": "第二章 参数估计理论",
    "question": "Cramer-Rao 下界是所有无偏估计子所能够达到的最低方差，利用它可以定义最有效的估计子，常简称为(___)。",
    "text": "Cramer-Rao 下界是所有无偏估计子所能够达到的最低方差，利用它可以定义最有效的估计子，常简称为(优效估计子)。",
    "answers": ["优效估计子"]
  },
  {
    "id": 43,
    "chapter": "第二章 参数估计理论",
    "question": "衡量估计值与参数真实值之间误差的函数称为(___)，该函数需要满足(___)和(___)两个条件。",
    "text": "衡量估计值与参数真实值之间误差的函数称为(代价函数)，该函数需要满足(非负性)和(极小值)两个条件。",
    "answers": ["代价函数", "非负性", "极小值"]
  },
  {
    "id": 44,
    "chapter": "第二章 参数估计理论",
    "question": "常用的代价函数有(___) 、(___)和(___)。",
    "text": "常用的代价函数有(误差平方代价函数) 、(误差绝对值代价函数)和(均匀代价函数)。",
    "answers": ["误差平方代价函数", "误差绝对值代价函数", "均匀代价函数"]
  },
  {
    "id": 45,
    "chapter": "第二章 参数估计理论",
    "question": "贝叶斯估计的本质是通过(___)得到参数θ 的最优估计，使得总期望风险(___)。",
    "text": "贝叶斯估计的本质是通过(贝叶斯决策)得到参数θ 的最优估计，使得总期望风险(最小)。",
    "answers": ["贝叶斯决策", "最小"]
  },
  {
    "id": 46,
    "chapter": "第二章 参数估计理论",
    "question": "假设被估计量θ 的先验概率密度函数为 p (θ )， 代价函数是随机变量θ 和观测信号 X 的函数，因此平均代价函数为(___)。",
    "text": "假设被估计量θ 的先验概率密度函数为 p (θ )， 代价函数是随机变量θ 和观测信号 X 的函数，因此平均代价函数为( C p (x,θ)dxdθ )。",
    "answers": [" C p (x,θ)dxdθ "]
  },
  {
    "id": 47,
    "chapter": "第二章 参数估计理论",
    "question": "贝叶斯估计是指从(___)和(___)出发，不同于最大似然估计，不再把参数θ 看成一个(___)，而是看成(___)，通过对第i 类样本 Di 的观察，使前向概率 P (Di /θ)转化为后验概率 P (θDi ) ，再求贝叶斯估计。",
    "text": "贝叶斯估计是指从(参数的先验知识)和(样本)出发，不同于最大似然估计，不再把参数θ 看成一个(未知的确定变量)，而是看成(未知的随机变量)，通过对第i 类样本 Di 的观察，使前向概率 P (Di /θ)转化为后验概率 P (θDi ) ，再求贝叶斯估计。",
    "answers": ["参数的先验知识", "样本", "未知的确定变量", "未知的随机变量"]
  },
  {
    "id": 48,
    "chapter": "第二章 参数估计理论",
    "question": "贝叶斯估计是把待估的参数θ 作为具有某种(___) p (θ )的随机变量， 通过随机样本 x 对θ 的分布进行修正，由样本x 进行修正后的概率密度 p (θx )称为(___)。",
    "text": "贝叶斯估计是把待估的参数θ 作为具有某种(先验概率分布) p (θ )的随机变量， 通过随机样本 x 对θ 的分布进行修正，由样本x 进行修正后的概率密度 p (θx )称为(后验概率)。",
    "answers": ["先验概率分布", "后验概率"]
  },
  {
    "id": 49,
    "chapter": "第二章 参数估计理论",
    "question": "先验概率分布 p (θ )已知，一般容易获取样本 x 关于θ 的条件概率密度函数 p (xθ) ，则根据贝叶斯公式可得后验概率密度函数",
    "text": "先验概率分布 p (θ )已知，一般容易获取样本 x 关于θ 的条件概率密度函数 p (xθ) ，则根据贝叶斯公式可得后验概率密度函数",
    "answers": []
  },
  {
    "id": 50,
    "chapter": "第二章 参数估计理论",
    "question": "在贝叶斯估计步骤中， (1)确定θ 的先验概率密度 p (θ ) ；(2)确定样本 x 的 条件概率密度p (xθ) ， 它 是 θ 的 函 数 ； (3) 利 用 贝 叶 斯 公 式 ， 求 θ 的 后 验 概 率p (4)计算参数θ 的贝叶斯估计",
    "text": "在贝叶斯估计步骤中， (1)确定θ 的先验概率密度 p (θ ) ；(2)确定样本 x 的 条件概率密度p (xθ) ， 它 是 θ 的 函 数 ； (3) 利 用 贝 叶 斯 公 式 ， 求 θ 的 后 验 概 率p (4)计算参数θ 的贝叶斯估计",
    "answers": []
  },
  {
    "id": 51,
    "chapter": "第二章 参数估计理论",
    "question": "似然函数是一种关于统计模型中的参数的函数，表示模型参数的(___)。",
    "text": "似然函数是一种关于统计模型中的参数的函数，表示模型参数的(似然性)。",
    "answers": ["似然性"]
  },
  {
    "id": 52,
    "chapter": "第二章 参数估计理论",
    "question": "在对被估计的未知量(或参数)没有任何先验知识的情况下，利用已知的若干观测值估计该参数。因此， 在使用(___)方法时，被估计的参数假定是常数，但未知；而已知的观测数据则是随机变量。",
    "text": "在对被估计的未知量(或参数)没有任何先验知识的情况下，利用已知的若干观测值估计该参数。因此， 在使用(最大似然估计)方法时，被估计的参数假定是常数，但未知；而已知的观测数据则是随机变量。",
    "answers": ["最大似然估计"]
  },
  {
    "id": 53,
    "chapter": "第二章 参数估计理论",
    "question": "(___)是指在参数已知的情况下，预测观测结果",
    "text": "(概率)是指在参数已知的情况下，预测观测结果",
    "answers": ["概率"]
  },
  {
    "id": 54,
    "chapter": "第二章 参数估计理论",
    "question": "(___)是指在观测结果已知的情况下，对参数进行估值和猜测。",
    "text": "(似然性)是指在观测结果已知的情况下，对参数进行估值和猜测。",
    "answers": ["似然性"]
  },
  {
    "id": 55,
    "chapter": "第二章 参数估计理论",
    "question": "最大似然估计常用来估计(___)或者(___)。",
    "text": "最大似然估计常用来估计(未知的非随机参量)或者(概率密度函数未知的随机参量)。",
    "answers": ["未知的非随机参量", "概率密度函数未知的随机参量"]
  },
  {
    "id": 56,
    "chapter": "第二章 参数估计理论",
    "question": "Bayes 估计需要已知先验概率密度 p (θ )和条件概率密度 p (xθ) ，而最大似然估计则需要已知似然函数 f (x1 , x2 , , xN θ)。但是， 在很多实际情况下，它们是未知的。另外，最大似然估计有时会导致(___)问题，不容易求解。因此， 不需要先验知识、并且容易实现的线性估计方法是(___)和(___)。",
    "text": "Bayes 估计需要已知先验概率密度 p (θ )和条件概率密度 p (xθ) ，而最大似然估计则需要已知似然函数 f (x1 , x2 , , xN θ)。但是， 在很多实际情况下，它们是未知的。另外，最大似然估计有时会导致(非线性估计)问题，不容易求解。因此， 不需要先验知识、并且容易实现的线性估计方法是(线性均方估计)和(最小二乘估计)。",
    "answers": ["非线性估计", "线性均方估计", "最小二乘估计"]
  },
  {
    "id": 57,
    "chapter": "第二章 参数估计理论",
    "question": "在线性均方估计中，待定的参数估计子被表示为观测数据的(___)，已知观测样本为 xi (i = 1, 2, , N ) ，则参数 θ 的估计值可以写为 ai xi + b ， 估计量的均方误差为 E 。线性均方估计通过选择最佳系数 ai 和b ，使得估计量的(___)最小。",
    "text": "在线性均方估计中，待定的参数估计子被表示为观测数据的(线性加权和)，已知观测样本为 xi (i = 1, 2, , N ) ，则参数 θ 的估计值可以写为 ai xi + b ， 估计量的均方误差为 E 。线性均方估计通过选择最佳系数 ai 和b ，使得估计量的(均方误差)最小。",
    "answers": ["线性加权和", "均方误差"]
  },
  {
    "id": 58,
    "chapter": "第二章 参数估计理论",
    "question": "均方误差最小，当且仅当估计误差e 正交于每一个给定的观测数据 xi ，其中 i = 1, 2, , N ，称为(___)。",
    "text": "均方误差最小，当且仅当估计误差e 正交于每一个给定的观测数据 xi ，其中 i = 1, 2, , N ，称为(正交性原理)。",
    "answers": ["正交性原理"]
  },
  {
    "id": 59,
    "chapter": "第二章 参数估计理论",
    "question": "当误差向量e 的各分量不仅具有(___)，而且还(___)时，最小二乘估计具有最小的估计方差，因而是最优的。如果误差向量各分量具有(___)，或者各分量之间(___)时，最小二乘估计就不再具有最小的估计方差，因而不会是最优的。",
    "text": "当误差向量e 的各分量不仅具有(相同的方差)，而且还(不相关)时，最小二乘估计具有最小的估计方差，因而是最优的。如果误差向量各分量具有(不同的方差)，或者各分量之间(相关)时，最小二乘估计就不再具有最小的估计方差，因而不会是最优的。",
    "answers": ["相同的方差", "不相关", "不同的方差", "相关"]
  }
]
